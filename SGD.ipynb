{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a10bc2-09db-4ef6-8400-65bca4cc5efe",
   "metadata": {},
   "source": [
    "<h2>Stochastic Gradient Descent (SGD)</h2>\n",
    "\n",
    "<h3>What is SGD?</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> SGD updates the model‚Äôs parameters using a single training example (or a small mini-batch) at a time. It is a faster and more memory-efficient version of gradient descent.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> SGD ‡¶π‡¶≤ ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø, ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ (‡¶¨‡¶æ ‡¶õ‡ßã‡¶ü ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö) ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá gradient ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ì weight ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§ ‡¶è‡¶ü‡¶ø ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶Æ ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Update Rule</h3>\n",
    "<ul>\n",
    "  <li><b>Formula:</b> \n",
    "    <br>Œ∏ = Œ∏ ‚àí Œ∑ √ó ‚àáJ(Œ∏; x<sup>(i)</sup>, y<sup>(i)</sup>)\n",
    "  </li>\n",
    "  <li><b>Where:</b>\n",
    "    <ul>\n",
    "      <li>Œ∏ = model parameters</li>\n",
    "      <li>Œ∑ = learning rate</li>\n",
    "      <li>‚àáJ = gradient of the cost function</li>\n",
    "      <li>x<sup>(i)</sup>, y<sup>(i)</sup> = a single training sample</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<h3>Advantages</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Fast updates, low memory usage, useful for large datasets.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá, ‡¶ï‡¶Æ ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶≤‡¶æ‡¶ó‡ßá ‡¶è‡¶¨‡¶Ç ‡¶¨‡ßú ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ï‡¶æ‡¶∞‡ßç‡¶Ø‡¶ï‡¶∞‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Disadvantages</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Noisy updates, may overshoot minima, hard to converge smoothly.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> ‡¶ï‡¶ñ‡¶®‡ßã ‡¶ï‡¶ñ‡¶®‡ßã ‡¶ñ‡ßÅ‡¶¨ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶â‡¶†‡¶æ‡¶®‡¶æ‡¶Æ‡¶æ ‡¶ï‡¶∞‡ßá, ‡¶´‡¶≤‡ßá ‡¶®‡¶ø‡¶ñ‡ßÅ‡¶Å‡¶§ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá ‡¶™‡ßå‡¶Å‡¶õ‡¶æ‡¶®‡ßã ‡¶ï‡¶†‡¶ø‡¶® ‡¶π‡ßü‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Techniques to Improve SGD</h3>\n",
    "<ul>\n",
    "  <li><b>Mini-Batch SGD:</b> Use a small group of samples instead of one ‚Üí more stable.</li>\n",
    "  <li><b>Momentum:</b> Add a fraction of previous gradient ‚Üí reduces oscillation.</li>\n",
    "  <li><b>Learning Rate Decay:</b> Reduce Œ∑ over time ‚Üí helps convergence.</li>\n",
    "</ul>\n",
    "\n",
    "<h3> Where is SGD Used?</h3>\n",
    "<ul>\n",
    "  <li>Neural Networks</li>\n",
    "  <li>Logistic/Linear Regression</li>\n",
    "  <li>Deep Learning with large datasets</li>\n",
    "</ul>\n",
    "\n",
    "<h3> SGD in Keras</h3>\n",
    "\n",
    "<pre>\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Basic usage\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "\n",
    "# With momentum\n",
    "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Compile with model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "</pre>\n",
    "\n",
    "<h3>üìä Summary Table</h3>\n",
    "<table border=\"1\" cellpadding=\"5\">\n",
    "  <tr>\n",
    "    <th>Aspect</th>\n",
    "    <th>SGD</th>\n",
    "    <th>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Update</td>\n",
    "    <td>One sample at a time</td>\n",
    "    <td>‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Speed</td>\n",
    "    <td>Fast</td>\n",
    "    <td>‡¶¶‡ßç‡¶∞‡ßÅ‡¶§</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stability</td>\n",
    "    <td>Low (oscillations)</td>\n",
    "    <td>‡¶ï‡¶Æ (‡¶ì‡¶†‡¶æ‡¶®‡¶æ‡¶Æ‡¶æ ‡¶ï‡¶∞‡ßá)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Best for</td>\n",
    "    <td>Large datasets</td>\n",
    "    <td>‡¶¨‡ßú ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f0de7-6044-4160-aa03-e893bf871592",
   "metadata": {},
   "source": [
    "## Mini Batch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6338689-e42b-404f-8748-bd362b3b397a",
   "metadata": {},
   "source": [
    "<h2>Mini-Batch Stochastic Gradient Descent (Mini-Batch SGD)</h2>\n",
    "\n",
    "<h3>What is Mini-Batch SGD?</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Mini-Batch SGD updates model weights using a small batch of training samples (e.g., 16, 32, 64). It combines the efficiency of batch gradient descent with the speed of stochastic gradient descent.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> Mini-Batch SGD ‡¶π‡¶≤ ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶õ‡ßã‡¶ü ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ (batch) ‡¶°‡ßá‡¶ü‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶ì‡¶ú‡¶® ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü (‡¶Ø‡ßá‡¶Æ‡¶® ‡ßß‡ß¨, ‡ß©‡ß® ‡¶¨‡¶æ ‡ß¨‡ß™)‡•§ ‡¶è‡¶ü‡¶ø Stochastic GD ‡¶ì Batch GD ‡¶è‡¶∞ ‡¶Æ‡¶ø‡¶∂‡ßç‡¶∞ ‡¶∞‡ßÇ‡¶™‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>How Does Mini-Batch SGD Work?</h3>\n",
    "<ol>\n",
    "  <li>Split training data into small batches (e.g., 32 samples each).</li>\n",
    "  <li>For each batch:\n",
    "    <ul>\n",
    "      <li>Calculate the average gradient of the loss function.</li>\n",
    "      <li>Update model weights using this gradient.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>Repeat this process for all batches in an epoch.</li>\n",
    "</ol>\n",
    "\n",
    "<p><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡ßü ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ß‡¶æ‡¶™:</b></p>\n",
    "<ol>\n",
    "  <li>‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü‡¶ï‡ßá ‡¶õ‡ßã‡¶ü ‡¶õ‡ßã‡¶ü ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§</li>\n",
    "  <li>‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø gradient ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü ‡¶è‡¶¨‡¶Ç ‡¶ì‡¶ú‡¶® ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§</li>\n",
    "  <li>‡¶è‡¶á ‡¶ï‡¶æ‡¶ú‡¶ü‡¶ø ‡¶∏‡¶¨ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡¶æ‡¶∞‡¶¨‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü (‡¶è‡¶ï‡¶ü‡¶ø epoch)‡•§</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Advantages of Mini-Batch SGD</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Faster than batch GD, more stable than SGD, suitable for parallel computing (GPU).</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> Batch GD ‡¶è‡¶∞ ‡¶ö‡ßá‡ßü‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶è‡¶¨‡¶Ç SGD ‡¶è‡¶∞ ‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡ßç‡¶•‡¶ø‡¶∞‡•§ GPU-‡¶§‡ßá efficiently ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Disadvantages of Mini-Batch SGD</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Choosing batch size can be tricky. Too small = noisy updates, too large = memory issues.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶æ‡¶á‡¶ú ‡¶¨‡¶æ‡¶õ‡¶æ‡¶á ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶†‡¶ø‡¶® ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§ ‡¶ñ‡ßÅ‡¶¨ ‡¶õ‡ßã‡¶ü ‡¶π‡¶≤‡ßá ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶Ö‡¶∏‡ßç‡¶•‡¶ø‡¶∞, ‡¶¨‡ßú ‡¶π‡¶≤‡ßá ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Common Batch Sizes</h3>\n",
    "<ul>\n",
    "  <li>16, 32, 64, 128 ‚Äî depends on dataset size and GPU RAM.</li>\n",
    "  <li><b>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ:</b> ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶®‡¶§‡¶É ‡ßß‡ß¨, ‡ß©‡ß®, ‡ß¨‡ß™, ‡ßß‡ß®‡ßÆ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§ ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü ‡¶ì GPU-‡¶è‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞ ‡¶ï‡¶∞‡ßá‡•§</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Python (Keras) Example</h3>\n",
    "\n",
    "<pre>\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "</pre>\n",
    "\n",
    "<h3>Summary Table</h3>\n",
    "<table border=\"1\" cellpadding=\"5\">\n",
    "  <tr>\n",
    "    <th>Aspect</th>\n",
    "    <th>Mini-Batch SGD</th>\n",
    "    <th>‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Speed</td>\n",
    "    <td>Faster than Batch GD</td>\n",
    "    <td>Batch GD ‡¶è‡¶∞ ‡¶ö‡ßá‡ßü‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stability</td>\n",
    "    <td>More stable than SGD</td>\n",
    "    <td>SGD ‡¶è‡¶∞ ‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶∏‡ßç‡¶•‡¶ø‡¶∞</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Memory Usage</td>\n",
    "    <td>Moderate</td>\n",
    "    <td>‡¶Æ‡¶æ‡¶ù‡¶æ‡¶∞‡¶ø ‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Best for</td>\n",
    "    <td>Large datasets with GPU</td>\n",
    "    <td>‡¶¨‡ßú ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü ‡¶ì GPU</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd3385-81c2-4792-812b-4d5272ba9867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
