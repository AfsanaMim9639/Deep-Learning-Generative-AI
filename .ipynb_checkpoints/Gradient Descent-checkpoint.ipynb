{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72c9a92-dd8c-4f9f-8168-a048d870f881",
   "metadata": {},
   "source": [
    "<h2>Gradient Descent Optimizers</h2>\n",
    "\n",
    "<h3>1. Batch Gradient Descent</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Uses the entire dataset to compute gradients. More stable, but slower.</li>\n",
    "  <li><b>বাংলা:</b> পুরো ডেটাসেট ব্যবহার করে একবারে gradient হিসাব করে। স্থির কিন্তু ধীর।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>2. Stochastic Gradient Descent (SGD)</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Updates weights using only one data point at a time. Faster but more noisy.</li>\n",
    "  <li><b>বাংলা:</b> প্রতিটি data point এর জন্য আলাদাভাবে weight আপডেট করে। দ্রুত কিন্তু কম স্থির।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>3. Mini-Batch Gradient Descent</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Uses a small batch of data points to update weights. A balance between speed and stability.</li>\n",
    "  <li><b>বাংলা:</b> কিছু সংখ্যক data point একসাথে ব্যবহার করে। গতির ও স্থিরতার ভারসাম্য বজায় রাখে।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>4. Momentum</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Accelerates SGD by adding a fraction of the previous update to the current one.</li>\n",
    "  <li><b>বাংলা:</b> আগের আপডেটের কিছু অংশ বর্তমান আপডেটে যোগ করে দ্রুত convergence নিশ্চিত করে।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>5. Nesterov Accelerated Gradient (NAG)</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Like momentum but looks ahead before the update.</li>\n",
    "  <li><b>বাংলা:</b> Momentum এর মতো, তবে ওজন আপডেট করার আগে একধাপ এগিয়ে দেখে নেয়।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>6. AdaGrad</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Adjusts learning rate individually for each parameter, good for sparse data.</li>\n",
    "  <li><b>বাংলা:</b> প্রতিটি প্যারামিটারের জন্য আলাদা learning rate ব্যবহার করে। sparse ডেটার জন্য উপযুক্ত।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>7. RMSProp</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Improves AdaGrad by using a moving average of squared gradients.</li>\n",
    "  <li><b>বাংলা:</b> AdaGrad এর মতই কিন্তু gradient এর চলমান গড় ব্যবহার করে।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>8. Adam (Adaptive Moment Estimation)</h3>\n",
    "<ul>\n",
    "  <li><b>English:</b> Combines Momentum and RMSProp. Most commonly used optimizer.</li>\n",
    "  <li><b>বাংলা:</b> Momentum ও RMSProp এর সংমিশ্রণ। সবচেয়ে বেশি ব্যবহৃত হয়।</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Comparison Table</h3>\n",
    "<table border=\"1\" cellpadding=\"5\">\n",
    "  <tr>\n",
    "    <th>Optimizer</th>\n",
    "    <th>Speed</th>\n",
    "    <th>Stability</th>\n",
    "    <th>বাংলা মন্তব্য</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Batch GD</td>\n",
    "    <td>Slow</td>\n",
    "    <td>Very stable</td>\n",
    "    <td>ধীরে চলে, কিন্তু নির্ভরযোগ্য</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SGD</td>\n",
    "    <td>Fast</td>\n",
    "    <td>Unstable</td>\n",
    "    <td>দ্রুত কিন্তু ঘন ঘন ওঠানামা করে</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mini-Batch</td>\n",
    "    <td>Medium</td>\n",
    "    <td>Balanced</td>\n",
    "    <td>গতি ও স্থিরতার সমন্বয়</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Momentum</td>\n",
    "    <td>Faster than SGD</td>\n",
    "    <td>More stable</td>\n",
    "    <td>দ্রুত ও স্থির</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>NAG</td>\n",
    "    <td>Faster</td>\n",
    "    <td>Better convergence</td>\n",
    "    <td>ভবিষ্যৎ অনুমান করে আপডেট</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>AdaGrad</td>\n",
    "    <td>Good for sparse data</td>\n",
    "    <td>Learning rate decays fast</td>\n",
    "    <td>শিক্ষার হার দ্রুত হ্রাস পায়</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RMSProp</td>\n",
    "    <td>Fast</td>\n",
    "    <td>Stable</td>\n",
    "    <td>ধারাবাহিক উন্নতি</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Adam</td>\n",
    "    <td>Fastest</td>\n",
    "    <td>Most Stable</td>\n",
    "    <td>সবচেয়ে জনপ্রিয় ও শক্তিশালী</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h3>Recommendation</h3>\n",
    "<ul>\n",
    "  <li><b>Beginners:</b> Use <b>Adam</b> — it works well in most cases.</li>\n",
    "  <li><b>বাংলা:</b> নতুনদের জন্য Adam সবচেয়ে ভালো কাজ করে, কারণ এটি গতিও দেয় ও স্থিরও থাকে।</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271ff78-6a4f-4384-8943-754e4cdf41b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
